# Any new models that someone wants to integrate should be added here

# gpt models
[gpt-3.5-turbo]
context_length = 16385

[gpt-3.5-turbo-1106]
context_length = 16385

[gpt-4-turbo-preview]
context_length = 128000

[gpt-4-turbo]
context_length = 128000

[gpt-4o-mini]
context_length = 128000

# gemini models
[gemini-1.5-pro]
context_length = 2000000

[gemini-1.5-flash]
context_length = 1000000

# ollama models
[llama3.1]
context_length = 128000
model_id = meta-llama/Meta-Llama-3.1-8B

[llama3.1:70b]
context_length = 128000
model_id = meta-llama/Meta-Llama-3.1-70B

[gemma2]
context_length = 8192
model_id = google/gemma-2-9b

[gemma2:27b]
context_length = 8192
model_id = google/gemma-2-27b

[mistral-nemo]
context_length = 128000
model_id = mistralai/Mistral-Nemo-Instruct-2407

[mistral-large]
context_length = 128000
model_id = mistralai/Mistral-Large-Instruct-2407

[phi3]
context_length = 128000
model_id = microsoft/Phi-3-mini-128k-instruct

[phi3:14b]
context_length = 128000
model_id = microsoft/Phi-3-medium-128k-instruct

[mistral]
context_length = 32000
model_id = mistralai/Mistral-7B-Instruct-v0.2

[mixtral]
context_length = 32000
model_id = mistralai/Mixtral-8x7B-Instruct-v0.1

[mixtral:8x22b]
context_length = 64000
model_id = mistralai/Mixtral-8x22B-Instruct-v0.1

[codegemma]
context_length = 8192
model_id = google/codegemma-7b

[llama3]
context_length = 8192
model_id = meta-llama/Meta-Llama-3-8B

[llama3:70b]
context_length = 8192
model_id = meta-llama/Meta-Llama-3-70B

[gemma]
context_length = 8192
model_id = google/gemma-7b

[gemma:2b]
context_length = 8192
model_id = google/gemma-2b

[llama2]
context_length = 4096
model_id = meta-llama/Llama-2-7b

[llama2:13b]
context_length = 4096
model_id = meta-llama/Llama-2-13b

[llama2:70b]
context_length = 4096
model_id = meta-llama/Llama-2-70b

[codellama]
context_length = 16000
model_id = codellama/CodeLlama-7b-Instruct-hf

[codellama:13b]
context_length = 16000
model_id = codellama/CodeLlama-13b-Instruct-hf

[codellama:34b]
context_length = 16000
model_id = codellama/CodeLlama-34b-Instruct-hf

[codellama:70b]
context_length = 16000
model_id = codellama/CodeLlama-70b-Instruct-hf